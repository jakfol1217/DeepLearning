{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7052fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Data loading and augmentation\n",
    "\n",
    "def load_cifar10_dataloaders():\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    dataset_train = torchvision.datasets.CIFAR10(\".data\", download=True, transform=transform)\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128)\n",
    "    dataset_test = torchvision.datasets.CIFAR10(\".data\", download=True, train=False, transform=transform)\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128)\n",
    "    return dataloader_train, dataloader_test\n",
    "\n",
    "def load_cifar10_dataloaders_validation():\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    dataset = torchvision.datasets.CIFAR10(\".data\", download=True, transform=transform)\n",
    "    size_train = 0.9*len(dataset)\n",
    "    size_val = len(dataset) - size_train\n",
    "    dataset_train, dataset_val = torch.utils.data.random_split(dataset, [int(size_train), int(size_val)])\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128)\n",
    "    dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128)\n",
    "    dataset_test = torchvision.datasets.CIFAR10(\".data\", download=True, train=False, transform=transform)\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128)\n",
    "    return dataloader_train, dataloader_test, dataloader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b341806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File based on https://github.com/huyvnphan/PyTorch_CIFAR10/\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_classes=10, avgpool_size=(1,1)):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(avgpool_size)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * avgpool_size[0] * avgpool_size[1], 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    " # Create convolution part of VGG11_bn archhitecture\n",
    "def make_vgg11_bn_layers(cfg = None):\n",
    "    if cfg == None:\n",
    "        cfg = [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"]\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    " # Create VGG11_bn model\n",
    "def vgg11_bn(device=\"cpu\", num_classes=10):\n",
    "    model = VGG(make_vgg11_bn_layers(), num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "vgg_cfg = {\n",
    "    '8':  [64, 'M', 128, 'M', 256, 'M', 512, 'M', 512, 'M'],\n",
    "    '11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    '13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    '16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    '19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def eval_accuracy(model, dataloader, training_device='cpu'):\n",
    "    with torch.no_grad():\n",
    "        model.to(training_device)\n",
    "        correct = 0\n",
    "        all_so_far = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(training_device), labels.to(training_device)\n",
    "            pred = torch.argmax(model(inputs), dim=1)\n",
    "\n",
    "            all_so_far += labels.size().numel()\n",
    "            correct += torch.sum(pred.eq(labels)).item()\n",
    "    return correct/all_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc0dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_to_ram(model):\n",
    "    from copy import deepcopy\n",
    "    return deepcopy(model).cpu()\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience = 3, backup_method=backup_to_ram):\n",
    "        self.patience = patience\n",
    "        self.current = 0\n",
    "        \n",
    "        self.backup_method = backup_method\n",
    "        \n",
    "        self.best_backup = None\n",
    "        self.best_accuracy = 0.\n",
    "\n",
    "    def should_continue(self, accuracy, model = None):\n",
    "        if self.best_accuracy < accuracy:\n",
    "            self.current = 0\n",
    "            self.best_accuracy = accuracy\n",
    "            if model is not None:\n",
    "                self.best_backup = self.backup_method(model)\n",
    "            return True\n",
    "        \n",
    "        self.current += 1\n",
    "        \n",
    "        if self.current >= self.patience:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d055caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, criterion, dataloader_train, training_device):\n",
    "    for inputs, labels in dataloader_train:\n",
    "        inputs, labels = inputs.to(training_device), labels.to(training_device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(inputs), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def train_one_run(model, optimizer, criterion, dataloader_train, dataloader_val, max_epochs, early_stopper, trajectory, training_device='cuda', *_args, **_kwargs):\n",
    "    model.train()\n",
    "    model.to(training_device)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_one_epoch(model, optimizer, criterion, dataloader_train, training_device)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        training_accuracy = eval_accuracy(model, dataloader_train, training_device)\n",
    "        validation_accuracy = eval_accuracy(model, dataloader_val, training_device)\n",
    "        print(\"Epoch: {}, Accuracy on validation set: {}\".format(epoch, validation_accuracy))\n",
    "        \n",
    "        trajectory.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train\": training_accuracy,\n",
    "            \"validation\": validation_accuracy,\n",
    "            \"start_time\": start_time,\n",
    "            \"duration\": end_time - start_time,\n",
    "            \"memory_allocated_mb\": torch.cuda.memory_allocated()/1024/1024,\n",
    "            \"memory_reserved_mb\": torch.cuda.memory_reserved()/1024/1024,\n",
    "        })\n",
    "        \n",
    "        \n",
    "        if not early_stopper.should_continue(validation_accuracy, model):\n",
    "            print(\"Early stop\")\n",
    "            return early_stopper.best_backup\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02660cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_arch_experiment(arch_name, model_factory, run):\n",
    "    path = \"experiments/arch_\" + arch_name + \"_\" + run + \"_\"\n",
    "    \n",
    "    # \n",
    "    import os\n",
    "    try:\n",
    "        if os.stat(path + \"report.json\").st_size != 0:\n",
    "            print(\"Report exists already for \" + path[:-2] + \". Skipping\")\n",
    "            return\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    train, test, val = load_cifar10_dataloaders_validation()\n",
    "    model = model_factory()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    early_stopper = EarlyStopper(patience = 5)\n",
    "    trajectory = []\n",
    "    model = train_one_run(model, optimizer, criterion, train, val, 200, early_stopper, trajectory)\n",
    "    validation_accuracy = eval_accuracy(model, val, \"cuda\")\n",
    "    \n",
    "    with open(path + \"report.json\", \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"name\": arch_name,\n",
    "                \"run\": run,\n",
    "                \"best_accuracy_validation\": validation_accuracy,\n",
    "                \"time_generated\": datetime.datetime.now().isoformat(),\n",
    "                \"trajectory\": trajectory\n",
    "            },\n",
    "            f\n",
    "        )\n",
    "    torch.save(model, path + \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a0094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_from_cfg(cfg_key):\n",
    "    return VGG(\n",
    "        make_vgg11_bn_layers(cfg=vgg_cfg[cfg_key]),\n",
    "        num_classes=10,\n",
    "        avgpool_size=(1,1)\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "def vgg8():\n",
    "    return vgg_from_cfg(\"8\")\n",
    "\n",
    "def vgg11_fat_classifier():\n",
    "    model = vgg_from_cfg(\"11\")\n",
    "    model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def vgg13():\n",
    "    return vgg_from_cfg(\"13\")\n",
    "\n",
    "def vgg16():\n",
    "    return vgg_from_cfg(\"16\")\n",
    "\n",
    "def vgg19():\n",
    "    return vgg_from_cfg(\"19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2bc1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = [\n",
    "    (factory.__name__, factory, str(run))\n",
    "    for factory in [vgg8, vgg11_fat_classifier, vgg13, vgg16, vgg19]\n",
    "    for run in range(1, 11)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c45ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2023-03-15T17:49:39.867764 Arch:  vgg8 Run:  1\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, Accuracy on validation set: 0.5778\n",
      "Epoch: 1, Accuracy on validation set: 0.6852\n",
      "Epoch: 2, Accuracy on validation set: 0.7256\n",
      "Epoch: 3, Accuracy on validation set: 0.7404\n",
      "Epoch: 4, Accuracy on validation set: 0.7588\n",
      "Epoch: 5, Accuracy on validation set: 0.7604\n",
      "Epoch: 6, Accuracy on validation set: 0.779\n",
      "Epoch: 7, Accuracy on validation set: 0.7926\n",
      "Epoch: 8, Accuracy on validation set: 0.7824\n",
      "Epoch: 9, Accuracy on validation set: 0.786\n",
      "Epoch: 10, Accuracy on validation set: 0.7838\n",
      "Epoch: 11, Accuracy on validation set: 0.7918\n",
      "Epoch: 12, Accuracy on validation set: 0.792\n",
      "Early stop\n",
      "Time: 2023-03-15T17:53:52.976009 Arch:  vgg8 Run:  2\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "for experiment in experiment_list:\n",
    "    print(\n",
    "        \"Time:\", datetime.datetime.now().isoformat(), \n",
    "        \"Arch: \", experiment[0], \n",
    "        \"Run: \", experiment[2]\n",
    "    )\n",
    "    run_arch_experiment(*experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0d621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
