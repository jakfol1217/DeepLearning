{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c363a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kacper\n"
     ]
    }
   ],
   "source": [
    "# code adapted from https://github.com/eriklindernoren/PyTorch-GAN\n",
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7738f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.n_epochs = 200\n",
    "        self.batch_size = 64\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.n_cpu = 8\n",
    "        self.latent_dim = 100\n",
    "        self.img_size = 64\n",
    "        self.channels = 3\n",
    "        self.sample_interval = 400\n",
    "\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cc55852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = opt.img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(opt.channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997c85eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Dropout2d(p=0.25, inplace=False)\n",
       "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): Dropout2d(p=0.25, inplace=False)\n",
       "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (adv_layer): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ae3a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepLearning.Project3 import data\n",
    "dataloader = data.load_dataloader_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d9d947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, time: 2023-06-03T19:43:04.044319\n",
      "Epoch: 1, time: 2023-06-03T19:50:40.333115\n",
      "Epoch: 2, time: 2023-06-03T19:57:48.018078\n",
      "Epoch: 3, time: 2023-06-03T20:04:48.118206\n",
      "Epoch: 4, time: 2023-06-03T20:11:19.458123\n",
      "Epoch: 5, time: 2023-06-03T20:17:22.346088\n",
      "Epoch: 6, time: 2023-06-03T20:23:07.650194\n",
      "Epoch: 7, time: 2023-06-03T20:29:04.765089\n",
      "Epoch: 8, time: 2023-06-03T20:34:43.171764\n",
      "Epoch: 9, time: 2023-06-03T20:40:40.380958\n",
      "Epoch: 10, time: 2023-06-03T20:46:24.976626\n",
      "Epoch: 11, time: 2023-06-03T20:52:24.350306\n",
      "Epoch: 12, time: 2023-06-03T20:58:34.963411\n",
      "Epoch: 13, time: 2023-06-03T21:04:34.249639\n",
      "Epoch: 14, time: 2023-06-03T21:10:46.233252\n",
      "Epoch: 15, time: 2023-06-03T21:16:38.445456\n",
      "Epoch: 16, time: 2023-06-03T21:22:16.937353\n",
      "Epoch: 17, time: 2023-06-03T21:27:49.730707\n",
      "Epoch: 18, time: 2023-06-03T21:33:30.406871\n",
      "Epoch: 19, time: 2023-06-03T21:39:36.428251\n",
      "Epoch: 20, time: 2023-06-03T21:45:57.340682\n",
      "Epoch: 21, time: 2023-06-03T21:51:27.157363\n",
      "Epoch: 22, time: 2023-06-03T21:56:56.642887\n",
      "Epoch: 23, time: 2023-06-03T22:02:49.063435\n",
      "Epoch: 24, time: 2023-06-03T22:08:32.591532\n",
      "Epoch: 25, time: 2023-06-03T22:14:09.298759\n",
      "Epoch: 26, time: 2023-06-03T22:19:38.617983\n",
      "Epoch: 27, time: 2023-06-03T22:25:43.858587\n",
      "Epoch: 28, time: 2023-06-03T22:31:38.480697\n",
      "Epoch: 29, time: 2023-06-03T22:37:10.872178\n",
      "Epoch: 30, time: 2023-06-03T22:42:38.721547\n",
      "Epoch: 31, time: 2023-06-03T22:48:43.348243\n",
      "Epoch: 32, time: 2023-06-03T22:54:15.723481\n",
      "Epoch: 33, time: 2023-06-03T23:00:10.654766\n",
      "Epoch: 34, time: 2023-06-03T23:05:39.704691\n",
      "Epoch: 35, time: 2023-06-03T23:11:13.726190\n",
      "Epoch: 36, time: 2023-06-03T23:16:55.887630\n",
      "Epoch: 37, time: 2023-06-03T23:22:59.560987\n",
      "Epoch: 38, time: 2023-06-03T23:28:30.338303\n",
      "Epoch: 39, time: 2023-06-03T23:33:59.976486\n",
      "Epoch: 40, time: 2023-06-03T23:39:30.953104\n",
      "Epoch: 41, time: 2023-06-03T23:45:00.070274\n",
      "Epoch: 42, time: 2023-06-03T23:50:47.887968\n",
      "Epoch: 43, time: 2023-06-03T23:56:48.218022\n",
      "Epoch: 44, time: 2023-06-04T00:02:40.649436\n",
      "Epoch: 45, time: 2023-06-04T00:08:10.925027\n",
      "Epoch: 46, time: 2023-06-04T00:13:41.707458\n",
      "Epoch: 47, time: 2023-06-04T00:19:10.809368\n",
      "Epoch: 48, time: 2023-06-04T00:24:39.139727\n",
      "Epoch: 49, time: 2023-06-04T00:30:09.137936\n",
      "Epoch: 50, time: 2023-06-04T00:35:40.004514\n",
      "Epoch: 51, time: 2023-06-04T00:41:18.105279\n",
      "Epoch: 52, time: 2023-06-04T00:47:18.783161\n",
      "Epoch: 53, time: 2023-06-04T00:52:56.789222\n",
      "Epoch: 54, time: 2023-06-04T00:58:31.646717\n",
      "Epoch: 55, time: 2023-06-04T01:04:17.798231\n",
      "Epoch: 56, time: 2023-06-04T01:09:45.002125\n",
      "Epoch: 57, time: 2023-06-04T01:15:11.620998\n",
      "Epoch: 58, time: 2023-06-04T01:20:52.822475\n",
      "Epoch: 59, time: 2023-06-04T01:27:09.059024\n",
      "Epoch: 60, time: 2023-06-04T01:32:52.280353\n",
      "Epoch: 61, time: 2023-06-04T01:38:18.699864\n",
      "Epoch: 62, time: 2023-06-04T01:43:48.733074\n",
      "Epoch: 63, time: 2023-06-04T01:49:25.317222\n",
      "Epoch: 64, time: 2023-06-04T01:54:54.676300\n",
      "Epoch: 65, time: 2023-06-04T02:01:00.035582\n",
      "Epoch: 66, time: 2023-06-04T02:06:41.690603\n",
      "Epoch: 67, time: 2023-06-04T02:12:12.723832\n",
      "Epoch: 68, time: 2023-06-04T02:17:40.577829\n",
      "Epoch: 69, time: 2023-06-04T02:23:05.159290\n",
      "Epoch: 70, time: 2023-06-04T02:28:31.644136\n",
      "Epoch: 71, time: 2023-06-04T02:34:20.274185\n",
      "Epoch: 72, time: 2023-06-04T02:40:15.536274\n",
      "Epoch: 73, time: 2023-06-04T02:45:42.916693\n",
      "Epoch: 74, time: 2023-06-04T02:51:21.898997\n",
      "Epoch: 75, time: 2023-06-04T02:57:12.457426\n",
      "Epoch: 76, time: 2023-06-04T03:02:55.198721\n",
      "Epoch: 77, time: 2023-06-04T03:08:30.082993\n",
      "Epoch: 78, time: 2023-06-04T03:14:46.401684\n",
      "Epoch: 79, time: 2023-06-04T03:20:27.222586\n",
      "Epoch: 80, time: 2023-06-04T03:25:56.458412\n",
      "Epoch: 81, time: 2023-06-04T03:31:37.045066\n",
      "Epoch: 82, time: 2023-06-04T03:37:06.436692\n",
      "Epoch: 83, time: 2023-06-04T03:42:36.193654\n",
      "Epoch: 84, time: 2023-06-04T03:48:05.885868\n",
      "Epoch: 85, time: 2023-06-04T03:53:33.964288\n",
      "Epoch: 86, time: 2023-06-04T03:59:03.067938\n",
      "Epoch: 87, time: 2023-06-04T04:04:29.725977\n",
      "Epoch: 88, time: 2023-06-04T04:09:57.127249\n",
      "Epoch: 89, time: 2023-06-04T04:15:22.284903\n",
      "Epoch: 90, time: 2023-06-04T04:20:49.743679\n",
      "Epoch: 91, time: 2023-06-04T04:26:40.917864\n",
      "Epoch: 92, time: 2023-06-04T04:32:20.985622\n",
      "Epoch: 93, time: 2023-06-04T04:38:24.182602\n",
      "Epoch: 94, time: 2023-06-04T04:44:19.531669\n",
      "Epoch: 95, time: 2023-06-04T04:50:00.036750\n",
      "Epoch: 96, time: 2023-06-04T04:55:48.336262\n",
      "Epoch: 97, time: 2023-06-04T05:01:33.519090\n",
      "Epoch: 98, time: 2023-06-04T05:07:16.216544\n",
      "Epoch: 99, time: 2023-06-04T05:13:04.163369\n",
      "Epoch: 100, time: 2023-06-04T05:18:46.859919\n",
      "Epoch: 101, time: 2023-06-04T05:24:32.939168\n",
      "Epoch: 102, time: 2023-06-04T05:30:20.132771\n",
      "Epoch: 103, time: 2023-06-04T05:36:13.515074\n",
      "Epoch: 104, time: 2023-06-04T05:41:59.791767\n",
      "Epoch: 105, time: 2023-06-04T05:47:36.890478\n",
      "Epoch: 106, time: 2023-06-04T05:53:21.419585\n",
      "Epoch: 107, time: 2023-06-04T05:59:25.057923\n",
      "Epoch: 108, time: 2023-06-04T06:05:14.641048\n",
      "Epoch: 109, time: 2023-06-04T06:10:56.466014\n",
      "Epoch: 110, time: 2023-06-04T06:16:40.982414\n",
      "Epoch: 111, time: 2023-06-04T06:22:22.202205\n",
      "Epoch: 112, time: 2023-06-04T06:27:55.036981\n",
      "Epoch: 113, time: 2023-06-04T06:34:10.362577\n",
      "Epoch: 114, time: 2023-06-04T06:39:42.568515\n",
      "Epoch: 115, time: 2023-06-04T06:45:28.937374\n",
      "Epoch: 116, time: 2023-06-04T06:51:08.211701\n",
      "Epoch: 117, time: 2023-06-04T06:56:41.551712\n",
      "Epoch: 118, time: 2023-06-04T07:02:38.702643\n",
      "Epoch: 119, time: 2023-06-04T07:08:37.431140\n",
      "Epoch: 120, time: 2023-06-04T07:14:25.590093\n",
      "Epoch: 121, time: 2023-06-04T07:20:08.584987\n",
      "Epoch: 122, time: 2023-06-04T07:25:39.331223\n",
      "Epoch: 123, time: 2023-06-04T07:31:51.573926\n",
      "Epoch: 124, time: 2023-06-04T07:37:30.223060\n",
      "Epoch: 125, time: 2023-06-04T07:43:01.425846\n",
      "Epoch: 126, time: 2023-06-04T07:48:30.855182\n",
      "Epoch: 127, time: 2023-06-04T07:53:58.581255\n",
      "Epoch: 128, time: 2023-06-04T07:59:29.232119\n",
      "Epoch: 129, time: 2023-06-04T08:04:57.270796\n",
      "Epoch: 130, time: 2023-06-04T08:10:38.959768\n",
      "Epoch: 131, time: 2023-06-04T08:16:25.193999\n",
      "Epoch: 132, time: 2023-06-04T08:21:58.669508\n",
      "Epoch: 133, time: 2023-06-04T08:28:12.593966\n",
      "Epoch: 134, time: 2023-06-04T08:33:41.645233\n",
      "Epoch: 135, time: 2023-06-04T08:39:23.667390\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(opt\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39misoformat(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (imgs, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# Adversarial ground truths\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         valid \u001b[38;5;241m=\u001b[39m Variable(Tensor(imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m1.0\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m         fake \u001b[38;5;241m=\u001b[39m Variable(Tensor(imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0.0\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchvision/datasets/folder.py:231\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchvision/transforms/functional.py:163\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    162\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 163\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    166\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/PIL/Image.py:525\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaccess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exif \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    527\u001b[0m         deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_animated\u001b[39m\u001b[38;5;124m\"\u001b[39m, plural\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "with open('experiments_gan/cdgan_trajectory.json', 'w') as f:\n",
    "    f.write(\"[\")\n",
    "\n",
    "import datetime\n",
    "    \n",
    "for epoch in range(opt.n_epochs):\n",
    "    print(f\"Epoch: {epoch}, time: {datetime.datetime.isoformat(datetime.datetime.now())}\")\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with open('experiments_gan/cdgan_trajectory.json', 'a') as f:\n",
    "                print(\n",
    "                    '{\"Epoch\": %d, \"Batch\": %d, \"D loss\": %f, \"G loss\": %f},'\n",
    "                    % (epoch, i, d_loss.item(), g_loss.item()),\n",
    "                    file=f\n",
    "                )\n",
    "        \n",
    "        \n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/cdgan/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "    \n",
    "    torch.save(generator, f\"experiments_gan/cdgan_generator_epoch_{epoch}.pt\")\n",
    "    torch.save(discriminator, f\"experiments_gan/cdgan_discriminator_epoch_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9914f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
